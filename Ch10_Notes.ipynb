{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93f37ed",
   "metadata": {},
   "source": [
    "# Chapter 10 Notes: Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fb34d",
   "metadata": {},
   "source": [
    "# From Biological to Artificial Neurons\n",
    " - McCulloch Pitts 1943 computational paper\n",
    "## Logical Computatiosn with Neurons\n",
    " - Uses artificial binary neurons\n",
    " - Can perform basic logic functions like AND, OR, =, OR NOT \n",
    " - Cannot do XOR\n",
    "## The Perceptron \n",
    " - Frank Rosenblatt 1957\n",
    " - Threshold Logic Units (TLU) make up the perceptron\n",
    " - inputs and outputs are scalars\n",
    " - each input is associated with a weight\n",
    " - each TLU computes a weighted sum of its inputs\n",
    "    - z = $w_1x_1$ + $w_2x_2$ ... = **$x^T$w**\n",
    " - Then the TLU applies a step function to the result and outputs the result\n",
    "    - $h_w$(**x**) = step(z) where z = **$x^T$w**\n",
    " - Types of step functions for Preceptrons:\n",
    "    - Heaviside Step Function - 0 until z > 0, then 1\n",
    "    - Sign Step Function - -1 for z < 0,  0 for z=0, 1 for z>0\n",
    " - A single TLU can perform linear binary classification. \n",
    " - A perceptron is merely a single layer of TLUs and an input layer \n",
    " - The input layer also contains a bias neuron which always outputs 1\n",
    " - Perceptrons can do multi-class classification\n",
    " - Computing the outputs of a fully connected perceptron layer:\n",
    "    - $h_{W,b}$ = $\\phi$(**XW** + **b**)\n",
    "    - **X**  # instances by # features\n",
    "    - **W** wieght matrix, # input neurons by # artificial neurons (TLUs) \n",
    "    - **b** bias vector contains weights between bias neuron and all the TLUs. len= # TLUs\n",
    "    - $\\phi$ activation function \n",
    " - Learning Rule: reinforces the connections which help reduce the error\n",
    " - $w_{i,j}^{(next Step)}$ = w$_{i,j}$ + $\\eta$($y_j$ - $\\hat{y}_j$)$x_i$\n",
    "     - $x_i$ ith input value for this instance\n",
    "     - $\\hat{y}_j$ out put of jth output neuron for this instance\n",
    "     - $y_j$ tartget output for jth neuron for this instance\n",
    "     - $\\eta$ learning rate\n",
    " - Only works for linear problems\n",
    " - Perceptrons do not output a class probability\n",
    " - Perceptrons cannot perform XOR operations\n",
    " - MLP - Multi-Layer Perceptrons can do XOR and other thins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42aaacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-b25aeda76ff5>:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target == 0).astype(np.int) #1 for setosas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,(2,3)] #length/width of petal \n",
    "y = (iris.target == 0).astype(np.int) #1 for setosas\n",
    "\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0751a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X,y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e74175",
   "metadata": {},
   "source": [
    " ## The Multilayer Perceptron and Backpropagation\n",
    "- MLPs are composed of an input layer, 1 or more hidden layers, and an output layer.\n",
    "    - there is a bias TLU in each layer. This bias unit receives no input from previous layer.\n",
    "- the input layer consists of pass through units and the other layers are TLUs\n",
    "- Rumelhart, Hinton, and Williams 1986 introduced backpropagation\n",
    "- **Backpropagation** - computes the gradient with respect to every single model parameter and for all the layers. Accomplishes this in two passes through the network. Finds how to tweak the weights in order to reduce the error. \n",
    "    - handles instances in minibatches (e.g. 32 instances)\n",
    "    - an epoch is a single cycle through the whole dataset\n",
    "    - On the *forward pass* the instances are passed through the network and all the intermediate outputs are saved. \n",
    "    - error is measured by using a loss function which compares the actual output vs the desired output\n",
    "    - the chain rule is used to determine how much each output contributed to the error\n",
    "    - the algorithm works backwards, determining how much of these error contributions came from each connection in the next lower layer. It propagates the error gradient backwards through the network. \n",
    "    - gradient descent performed by tweaking all connections in the network using the error gradients just computed. \n",
    "- Step function is replaced by a sigmoid function so there is a gradient to follow. $\\sigma$ = $\\frac{1}{1 + e^{-z}}$\n",
    "    - this is an activation function like the hyperbolic tangent function or Rectified linear unit\n",
    "- non-linear activation functions allow the MLP to approximate non-linear continuous functions. \n",
    "\n",
    "## Regression MLPs\n",
    "- you need one output neuron per value you are trying to predict.\n",
    "    - home value: 1 neuron, size of a rectangle: 2 neurons\n",
    "- Usually you do not use an activation function for the output neurons. \n",
    "    - certain activation functions can bound the outputs within useful ranges\n",
    "- MSE is the typical loss funciton\n",
    "    - $\\frac{1}{n}$$\\sum\\limits_{i=1}^{n}$(y-$\\hat{y}$)$^2$\n",
    "\n",
    "## Classification MLPs\n",
    "- can output the estimated probability for binary classification with a single output neuron\n",
    "- You need one output neuron per class you are predicting\n",
    "    - Softmax activation funciton will ensure all the outputs sum to one. This is useful for exclusive multiclass classification\n",
    "    - cross entropy loss function is useful here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311a53c",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras\n",
    "- released in 2015\n",
    "- relies on computation backend (TF, CNTK, theano)\n",
    "- tensorflow has its own version of keras included. tf.keras\n",
    "## Installing TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d1b556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2481be24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0-dev20211217'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3000f",
   "metadata": {},
   "source": [
    "## Building an Image Classifier\n",
    "- Using fashion MNIST\n",
    "### Using keras to Load the Dataset\n",
    "- data represented as 28x28 arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307c1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "26435584/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181eb5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62875aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d08719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.max(X_train_full))\n",
    "print(np.min(X_train_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cae66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and scale the data (0 to 1)\n",
    "#data already shuffled\n",
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ae3a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coat',\n",
       " 'T-shirt/top',\n",
       " 'Sneaker',\n",
       " 'Ankle boot',\n",
       " 'Ankle boot',\n",
       " 'Ankle boot',\n",
       " 'Coat',\n",
       " 'Coat',\n",
       " 'Dress',\n",
       " 'Coat']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "[class_names[int(this_item)] for this_item in y_train[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d25ac",
   "metadata": {},
   "source": [
    "### Creating the model Using the Sequential API\n",
    "- sequential api is the simplest form of nn single stack of layers\n",
    "- add an input layer, preprocesses the data, reshaping the data to be 1D\n",
    "- add a dense layer with relu. Also manages the bias term for each neuron\n",
    "- add another layer, 100 neurons \n",
    "- add output layer, classes are exlusive \n",
    "- alternative syntax is to pass a list of layers when initializing the model\n",
    "\n",
    "- dense layers produce a lot of parameters \n",
    "- more parameters introduces risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc5d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and build the model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b862fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1592768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x257ab94e970>,\n",
       " <keras.layers.core.dense.Dense at 0x257ac3d0eb0>,\n",
       " <keras.layers.core.dense.Dense at 0x257ac60db20>,\n",
       " <keras.layers.core.dense.Dense at 0x257ac089a90>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c280f14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e3d9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62601c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8cc3697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6703c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use kernel_initializer to alter initialization parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f39b6",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3480dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b47434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d788d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
